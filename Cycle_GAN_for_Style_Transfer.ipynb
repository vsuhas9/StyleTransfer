{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1IV0BH7zNDcBY9BQfJgwZaX_wxj1heo4a",
      "authorship_tag": "ABX9TyNltfAhv+tafGevlbgy5CUg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsuhas9/StyleTransfer/blob/dev-suhas/Cycle_GAN_for_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries and Helper Functions"
      ],
      "metadata": {
        "id": "MMCNHdSdhkg8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVHLZN3bgLqm",
        "outputId": "0bdd1157-639c-49b2-e1eb-0b075428169e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "! pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Helper Functions for Generator and Discriminator\n",
        "def downsample(filters, size, apply_instancenorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = keras.Sequential()\n",
        "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "    if apply_instancenorm:\n",
        "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "    result.add(layers.LeakyReLU())\n",
        "    return result\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = keras.Sequential()\n",
        "    result.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                      kernel_initializer=initializer, use_bias=False))\n",
        "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "    if apply_dropout:\n",
        "        result.add(layers.Dropout(0.5))\n",
        "    result.add(layers.ReLU())\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the Generator and Descriminator Stack"
      ],
      "metadata": {
        "id": "-mQqvRFjhpFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Model\n",
        "def Generator(img_shape=[256, 256, 3]):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    inputs = layers.Input(shape=img_shape)\n",
        "\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_instancenorm=False),  # (bs, 128, 128, 64)\n",
        "        downsample(128, 4),  # (bs, 64, 64, 128)\n",
        "        downsample(256, 4),  # (bs, 32, 32, 256)\n",
        "        downsample(512, 4),  # (bs, 16, 16, 512)\n",
        "        downsample(512, 4),  # (bs, 8, 8, 512)\n",
        "        downsample(512, 4),  # (bs, 4, 4, 512)\n",
        "        downsample(512, 4),  # (bs, 2, 2, 512)\n",
        "        downsample(512, 4),  # (bs, 1, 1, 512)\n",
        "    ]\n",
        "\n",
        "    up_stack = [\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n",
        "        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n",
        "        upsample(512, 4),  # (bs, 16, 16, 1024)\n",
        "        upsample(256, 4),  # (bs, 32, 32, 512)\n",
        "        upsample(128, 4),  # (bs, 64, 64, 256)\n",
        "        upsample(64, 4),  # (bs, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    last = layers.Conv2DTranspose(3, 4, strides=2, padding='same',\n",
        "                                  kernel_initializer=initializer, activation='tanh')  # (bs, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = layers.Concatenate()([x, skip])\n",
        "    x = last(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# Discriminator Model\n",
        "def Discriminator(img_shape=[256, 256, 3]):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    inp = layers.Input(shape=img_shape, name='input_image')\n",
        "    x = inp\n",
        "\n",
        "    x = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n",
        "    x = downsample(128, 4)(x)  # (bs, 64, 64, 128)\n",
        "    x = downsample(256, 4)(x)  # (bs, 32, 32, 256)\n",
        "\n",
        "    x = layers.ZeroPadding2D()(x)  # (bs, 33, 33, 256)\n",
        "    x = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(x)  # (bs, 30, 30, 512)\n",
        "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.ZeroPadding2D()(x)  # (bs, 31, 31, 512)\n",
        "    x = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(x)  # (bs, 28, 28, 1)\n",
        "\n",
        "    return tf.keras.Model(inputs=inp, outputs=x)\n"
      ],
      "metadata": {
        "id": "9zhXcziYg7vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Defining Loss Functions"
      ],
      "metadata": {
        "id": "mxCFmVHchucp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real, generated):\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n",
        "    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "    return total_disc_loss * 0.5\n",
        "\n",
        "def generator_loss(generated):\n",
        "    return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)\n",
        "\n",
        "def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "    return LAMBDA * loss\n",
        "\n",
        "def identity_loss(real_image, same_image, LAMBDA):\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "    return LAMBDA * 0.5 * loss\n"
      ],
      "metadata": {
        "id": "__9IqJ7qh2Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step - 4: Cycle GAN CLass"
      ],
      "metadata": {
        "id": "5nmFNMJYjrgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGAN(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        monet_generator,\n",
        "        photo_generator,\n",
        "        monet_discriminator,\n",
        "        photo_discriminator,\n",
        "        lambda_cycle=10,\n",
        "    ):\n",
        "        super(CycleGAN, self).__init__()\n",
        "        self.m_gen = monet_generator\n",
        "        self.p_gen = photo_generator\n",
        "        self.m_disc = monet_discriminator\n",
        "        self.p_disc = photo_discriminator\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        m_gen_optimizer,\n",
        "        p_gen_optimizer,\n",
        "        m_disc_optimizer,\n",
        "        p_disc_optimizer,\n",
        "        gen_loss_fn,\n",
        "        disc_loss_fn,\n",
        "        cycle_loss_fn,\n",
        "        identity_loss_fn\n",
        "    ):\n",
        "        super(CycleGAN, self).compile()\n",
        "        self.m_gen_optimizer = m_gen_optimizer\n",
        "        self.p_gen_optimizer = p_gen_optimizer\n",
        "        self.m_disc_optimizer = m_disc_optimizer\n",
        "        self.p_disc_optimizer = p_disc_optimizer\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "        self.disc_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = cycle_loss_fn\n",
        "        self.identity_loss_fn = identity_loss_fn\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        real_monet, real_photo = batch_data\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Photo to monet back to photo\n",
        "            fake_monet = self.m_gen(real_photo, training=True)\n",
        "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
        "\n",
        "            # Monet to photo back to monet\n",
        "            fake_photo = self.p_gen(real_monet, training=True)\n",
        "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
        "\n",
        "            # Generating itself\n",
        "            same_monet = self.m_gen(real_monet, training=True)\n",
        "            same_photo = self.p_gen(real_photo, training=True)\n",
        "\n",
        "            # Discriminator used to check, inputting real images\n",
        "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
        "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
        "\n",
        "            # Discriminator used to check, inputting fake images\n",
        "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
        "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
        "\n",
        "            # Evaluate generator loss\n",
        "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
        "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
        "\n",
        "            # Evaluate total cycle consistency loss\n",
        "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
        "\n",
        "            # Evaluate total generator loss\n",
        "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
        "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
        "\n",
        "            # Evaluate discriminator loss\n",
        "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
        "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
        "\n",
        "        # Calculate the gradients for generator and discriminator\n",
        "        monet_generator_gradients = tape.gradient(total_monet_gen_loss, self.m_gen.trainable_variables)\n",
        "        photo_generator_gradients = tape.gradient(total_photo_gen_loss, self.p_gen.trainable_variables)\n",
        "        monet_discriminator_gradients = tape.gradient(monet_disc_loss, self.m_disc.trainable_variables)\n",
        "        photo_discriminator_gradients = tape.gradient(photo_disc_loss, self.p_disc.trainable_variables)\n",
        "\n",
        "        # Apply the gradients to the optimizer\n",
        "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients, self.m_gen.trainable_variables))\n",
        "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients, self.p_gen.trainable_variables))\n",
        "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients, self.m_disc.trainable_variables))\n",
        "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients, self.p_disc.trainable_variables))\n",
        "\n",
        "        return {\n",
        "            \"total_loss\": total_monet_gen_loss + total_photo_gen_loss + monet_disc_loss + photo_disc_loss,\n",
        "            \"monet_gen_loss\": total_monet_gen_loss,\n",
        "            \"photo_gen_loss\": total_photo_gen_loss,\n",
        "            \"monet_disc_loss\": monet_disc_loss,\n",
        "            \"photo_disc_loss\": photo_disc_loss\n",
        "        }\n",
        "\n",
        "    def generate(self, image):\n",
        "        return self.m_gen(tf.expand_dims(image, axis=0), training=False)\n",
        "\n",
        "    def load(\n",
        "        self,\n",
        "        filepath\n",
        "    ):\n",
        "        self.m_gen.load_weights(filepath.replace('model_name', 'm_gen'))\n",
        "        self.p_gen.load_weights(filepath.replace('model_name', 'p_gen'))\n",
        "        self.m_disc.load_weights(filepath.replace('model_name', 'm_disc'))\n",
        "        self.p_disc.load_weights(filepath.replace('model_name', 'p_disc'))\n",
        "\n",
        "    def save(\n",
        "        self,\n",
        "        filepath\n",
        "    ):\n",
        "        self.m_gen.save_weights(filepath.replace('model_name', 'm_gen'))\n",
        "        self.p_gen.save_weights(filepath.replace('model_name', 'p_gen'))\n",
        "        self.m_disc.save_weights(filepath.replace('model_name', 'm_disc'))\n",
        "        self.p_disc.save_weights(filepath.replace('model_name', 'p_disc'))\n"
      ],
      "metadata": {
        "id": "tkNzGHG5i-4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step - 5: Loading and preprocessing images"
      ],
      "metadata": {
        "id": "8HzKnhxUj0dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(path, img_shape):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=img_shape[-1])\n",
        "    img = tf.image.resize(img, img_shape[:2])\n",
        "    img = (img - 127.5) / 127.5  # Normalize the image to [-1, 1]\n",
        "    return img\n",
        "\n",
        "def create_dataset(target_paths, style_paths, img_shape, batch_size):\n",
        "    target_images = [load_and_preprocess_image(path, img_shape) for path in target_paths]\n",
        "    style_images = [load_and_preprocess_image(path, img_shape) for path in style_paths]\n",
        "\n",
        "    target_dataset = tf.data.Dataset.from_tensor_slices(target_images)\n",
        "    style_dataset = tf.data.Dataset.from_tensor_slices(style_images)\n",
        "\n",
        "    # Zip the two datasets and batch them\n",
        "    dataset = tf.data.Dataset.zip((target_dataset, style_dataset)).batch(batch_size)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "0rYCvj7VjqIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Initialize and Compile CycleGAN"
      ],
      "metadata": {
        "id": "JsRs-T3DkUOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = [256, 256, 3]\n",
        "\n",
        "model = CycleGAN(\n",
        "    monet_generator=Generator(img_shape),\n",
        "    photo_generator=Generator(img_shape),\n",
        "    monet_discriminator=Discriminator(img_shape),\n",
        "    photo_discriminator=Discriminator(img_shape),\n",
        "    lambda_cycle=10\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    m_gen_optimizer=tf.keras.optimizers.Adam(1e-4, beta_1=0.5),\n",
        "    p_gen_optimizer=tf.keras.optimizers.Adam(1e-4, beta_1=0.5),\n",
        "    m_disc_optimizer=tf.keras.optimizers.Adam(1e-4, beta_1=0.5),\n",
        "    p_disc_optimizer=tf.keras.optimizers.Adam(1e-4, beta_1=0.5),\n",
        "    gen_loss_fn=generator_loss,\n",
        "    disc_loss_fn=discriminator_loss,\n",
        "    cycle_loss_fn=calc_cycle_loss,\n",
        "    identity_loss_fn=identity_loss\n",
        ")\n"
      ],
      "metadata": {
        "id": "RqSwEhPgj_Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step - 7: Loading and Training the model"
      ],
      "metadata": {
        "id": "w5FcW-Tbkmej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files(folder_path):\n",
        "    files = []\n",
        "    for entry in os.listdir(folder_path):\n",
        "        if os.path.isfile(os.path.join(folder_path, entry)):\n",
        "            files.append( folder_path + entry)\n",
        "    return files\n",
        "\n",
        "# Example usage\n",
        "target_folder_path = '/content/drive/MyDrive/shared/gan-getting-started/photo_jpg/'\n",
        "style_folder_path = '/content/drive/MyDrive/shared/gan-getting-started/monet_jpg/'\n",
        "\n",
        "try:\n",
        "  target_image_paths =  list_files(target_folder_path)\n",
        "  style_image_paths = list_files(style_folder_path)[:25]\n",
        "  target_image_paths = target_image_paths[:len(style_image_paths)*2]\n",
        "\n",
        "  print(str(len(target_image_paths)) + \" Target Images loaded & \" + str(len(style_image_paths)) + \" Style Images loaded\" )\n",
        "except:\n",
        "  print(\"Error loading the files\")\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create dataset\n",
        "dataset = create_dataset(target_image_paths, style_image_paths, img_shape, batch_size)\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "history = model.fit(dataset, epochs=epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxFYOfaFkXFl",
        "outputId": "b260bd6b-1079-4d9d-ec47-aef910172a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 Target Images loaded & 25 Style Images loaded\n",
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step - 8: Display and Store the Images"
      ],
      "metadata": {
        "id": "UIdt0jwvl9jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def generate_display_save(target_dataset, model, num_samples, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create the output directory\n",
        "    dataset_iter = iter(target_dataset)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        img, _ = next(dataset_iter)  # Only use the target image\n",
        "        prediction = model.generate(img)\n",
        "        prediction = tf.squeeze(prediction).numpy()\n",
        "        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)  # Rescale the pixel values\n",
        "\n",
        "        # Display the image\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(prediction)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Save the image\n",
        "        plt.imsave(os.path.join(output_dir, f'image_{i:04d}.jpg'), prediction)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "generate_display_save(dataset, model, num_samples=5, output_dir='output')  # Adjust num_samples as needed\n"
      ],
      "metadata": {
        "id": "cgYZBobUl7-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GlIY9EQXlS_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}